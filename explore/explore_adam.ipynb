{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "building_id                                                   \n",
       "802906                    6             487           12198   \n",
       "28830                     8             900            2812   \n",
       "94947                    21             363            8973   \n",
       "590882                   22             418           10694   \n",
       "201944                   11             131            1488   \n",
       "\n",
       "             count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "building_id                                                                 \n",
       "802906                         2   30                6                  5   \n",
       "28830                          2   10                8                  7   \n",
       "94947                          2   10                5                  5   \n",
       "590882                         2   10                6                  5   \n",
       "201944                         3   30                8                  9   \n",
       "\n",
       "            land_surface_condition foundation_type roof_type  ...  \\\n",
       "building_id                                                   ...   \n",
       "802906                           t               r         n  ...   \n",
       "28830                            o               r         n  ...   \n",
       "94947                            t               r         n  ...   \n",
       "590882                           t               r         n  ...   \n",
       "201944                           t               r         n  ...   \n",
       "\n",
       "            has_secondary_use_agriculture has_secondary_use_hotel  \\\n",
       "building_id                                                         \n",
       "802906                                  0                       0   \n",
       "28830                                   0                       0   \n",
       "94947                                   0                       0   \n",
       "590882                                  0                       0   \n",
       "201944                                  0                       0   \n",
       "\n",
       "            has_secondary_use_rental has_secondary_use_institution  \\\n",
       "building_id                                                          \n",
       "802906                             0                             0   \n",
       "28830                              0                             0   \n",
       "94947                              0                             0   \n",
       "590882                             0                             0   \n",
       "201944                             0                             0   \n",
       "\n",
       "             has_secondary_use_school  has_secondary_use_industry  \\\n",
       "building_id                                                         \n",
       "802906                              0                           0   \n",
       "28830                               0                           0   \n",
       "94947                               0                           0   \n",
       "590882                              0                           0   \n",
       "201944                              0                           0   \n",
       "\n",
       "             has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "building_id                                                                \n",
       "802906                                   0                             0   \n",
       "28830                                    0                             0   \n",
       "94947                                    0                             0   \n",
       "590882                                   0                             0   \n",
       "201944                                   0                             0   \n",
       "\n",
       "             has_secondary_use_use_police  has_secondary_use_other  \n",
       "building_id                                                         \n",
       "802906                                  0                        0  \n",
       "28830                                   0                        0  \n",
       "94947                                   0                        0  \n",
       "590882                                  0                        0  \n",
       "201944                                  0                        0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values = pd.read_csv('../data/train_values.csv', index_col='building_id')\n",
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "802906                  3\n",
       "28830                   2\n",
       "94947                   3\n",
       "590882                  2\n",
       "201944                  3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('../data/train_labels.csv', index_col='building_id')\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land_surface_condition\n",
      "foundation_type\n",
      "roof_type\n",
      "ground_floor_type\n",
      "other_floor_type\n",
      "position\n",
      "plan_configuration\n",
      "legal_ownership_status\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns = \n",
    "categorical_columns = [c for c in train_values.select_dtypes(include=['object'])]\n",
    "for c in categorical_columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has_superstructure_bamboo',\n",
       " 'has_superstructure_mud_mortar_stone',\n",
       " 'has_secondary_use_school',\n",
       " 'has_superstructure_cement_mortar_brick',\n",
       " 'has_secondary_use_institution',\n",
       " 'has_secondary_use_gov_office',\n",
       " 'has_secondary_use',\n",
       " 'has_secondary_use_hotel',\n",
       " 'height_percentage',\n",
       " 'count_floors_pre_eq',\n",
       " 'has_secondary_use_other',\n",
       " 'area_percentage',\n",
       " 'has_secondary_use_health_post',\n",
       " 'count_families',\n",
       " 'age',\n",
       " 'has_secondary_use_agriculture',\n",
       " 'has_secondary_use_rental',\n",
       " 'has_superstructure_rc_engineered',\n",
       " 'has_secondary_use_industry',\n",
       " 'has_superstructure_adobe_mud',\n",
       " 'geo_level_2_id',\n",
       " 'has_secondary_use_use_police',\n",
       " 'geo_level_3_id',\n",
       " 'geo_level_1_id',\n",
       " 'has_superstructure_timber',\n",
       " 'has_superstructure_mud_mortar_brick',\n",
       " 'has_superstructure_other',\n",
       " 'has_superstructure_stone_flag',\n",
       " 'has_superstructure_rc_non_engineered',\n",
       " 'has_superstructure_cement_mortar_stone']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = list(set(train_values.columns) - set(categorical_columns))\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "building_id                                                   \n",
       "802906                    6             487           12198   \n",
       "28830                     8             900            2812   \n",
       "94947                    21             363            8973   \n",
       "590882                   22             418           10694   \n",
       "201944                   11             131            1488   \n",
       "\n",
       "             count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "building_id                                                                 \n",
       "802906                         2   30                6                  5   \n",
       "28830                          2   10                8                  7   \n",
       "94947                          2   10                5                  5   \n",
       "590882                         2   10                6                  5   \n",
       "201944                         3   30                8                  9   \n",
       "\n",
       "            land_surface_condition foundation_type roof_type  ...  \\\n",
       "building_id                                                   ...   \n",
       "802906                           t               r         n  ...   \n",
       "28830                            o               r         n  ...   \n",
       "94947                            t               r         n  ...   \n",
       "590882                           t               r         n  ...   \n",
       "201944                           t               r         n  ...   \n",
       "\n",
       "            has_secondary_use_agriculture has_secondary_use_hotel  \\\n",
       "building_id                                                         \n",
       "802906                                  0                       0   \n",
       "28830                                   0                       0   \n",
       "94947                                   0                       0   \n",
       "590882                                  0                       0   \n",
       "201944                                  0                       0   \n",
       "\n",
       "            has_secondary_use_rental has_secondary_use_institution  \\\n",
       "building_id                                                          \n",
       "802906                             0                             0   \n",
       "28830                              0                             0   \n",
       "94947                              0                             0   \n",
       "590882                             0                             0   \n",
       "201944                             0                             0   \n",
       "\n",
       "             has_secondary_use_school  has_secondary_use_industry  \\\n",
       "building_id                                                         \n",
       "802906                              0                           0   \n",
       "28830                               0                           0   \n",
       "94947                               0                           0   \n",
       "590882                              0                           0   \n",
       "201944                              0                           0   \n",
       "\n",
       "             has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "building_id                                                                \n",
       "802906                                   0                             0   \n",
       "28830                                    0                             0   \n",
       "94947                                    0                             0   \n",
       "590882                                   0                             0   \n",
       "201944                                   0                             0   \n",
       "\n",
       "             has_secondary_use_use_police  has_secondary_use_other  \n",
       "building_id                                                         \n",
       "802906                                  0                        0  \n",
       "28830                                   0                        0  \n",
       "94947                                   0                        0  \n",
       "590882                                  0                        0  \n",
       "201944                                  0                        0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_index_mask = train_values.index.duplicated(keep='first')\n",
    "train_values = train_values[~duplicate_index_mask]\n",
    "train_labels = train_labels[~duplicate_index_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop building_id (index) from X and y\n",
    "train_values.reset_index(drop=True, inplace=True)\n",
    "train_labels.reset_index(drop=True, inplace=True)\n",
    "# Convert y to a Series instead of a DataFrame\n",
    "train_labels = train_labels['damage_grade']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert geo data to categorical\n",
    "def fixup_geo_data(data):\n",
    "    geo_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "    for c in geo_cols:\n",
    "        data[c] = data[c].astype('object')\n",
    "fixup_geo_data(train_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_values, train_labels, train_size=0.8, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All possible values from all categorical columns are present in the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor_drop_cat():\n",
    "    return ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', 'drop', categorical_columns),\n",
    "        ('numerical', 'passthrough', numerical_columns),\n",
    "    ])\n",
    "\n",
    "def build_preprocessor_ordinal_enc():\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Bundle preprocessing pipeline\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_columns),\n",
    "            (\"numerical\", \"passthrough\", numerical_columns),\n",
    "        ])\n",
    "\n",
    "def build_preprocessor_target_enc():\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('target', TargetEncoder(target_type='continuous'))\n",
    "    ])\n",
    "\n",
    "    # Bundle preprocessing pipeline\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_columns),\n",
    "            (\"numerical\", \"passthrough\", numerical_columns),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = dict(\n",
    "    #drop_cat=build_preprocessor_drop_cat(),\n",
    "    #ordinal_enc_cat=build_preprocessor_ordinal_enc(),\n",
    "    target_enc_cat=build_preprocessor_target_enc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# the model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "#random_forest = GradientBoostingClassifier(n_estimators=100, random_state=57)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = {\"n_estimators\": (250, 350),\n",
    "                \"max_depth\": (5, 30),\n",
    "                \"learning_rate\": (0.02, 1.0, 'log-uniform'),\n",
    "                \"min_samples_split\": (2, 10),\n",
    "                \"min_samples_leaf\": (1, 10)}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "\n",
    "# Initialize the BayesSearchCV\n",
    "opt = BayesSearchCV(gbc, search_space, n_iter=50, cv=None, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass \n",
    "class EvaluatedModel:\n",
    "    name: str\n",
    "    pipeline: Pipeline\n",
    "    score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey-patch deprecated Numpy functions (still used by skopt)\n",
    "np.int = np.int_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "overdone_control = DeltaYStopper(delta=0.001)                    # We stop if the gain of the optimization becomes too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_via_pipeline(name, pipeline, model):\n",
    "    clf = Pipeline(\n",
    "       steps=[('preprocessor', pipeline),\n",
    "              ('model', model)])\n",
    "\n",
    "    X = X_train.copy()\n",
    "    y = y_train.copy()\n",
    "\n",
    "    #kwargs = {\"callback\": overdone_control}\n",
    "    kwargs = {\"X\":X_valid, \"y\":y_valid, \"model__callback\": overdone_control}\n",
    "    clf.fit(**kwargs)\n",
    "    score = clf.score(X=X_valid, y=y_valid)\n",
    "    print(f\"Evaluated model score: {score}\")\n",
    "    # Print the best parameters and score\n",
    "    print(\"Best parameters found: \", clf.best_params_)\n",
    "    print(\"Best score found: \", clf.best_score_)\n",
    "    return EvaluatedModel(name=name, pipeline=clf, score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.7859523653146779, max_depth=12, min_samples_leaf=4, min_samples_split=9, n_estimators=344;, score=0.690 total time= 3.2min\n",
      "[CV 1/5] END learning_rate=0.7859523653146779, max_depth=12, min_samples_leaf=4, min_samples_split=9, n_estimators=344;, score=0.677 total time= 3.6min\n",
      "[CV 2/5] END learning_rate=0.7859523653146779, max_depth=12, min_samples_leaf=4, min_samples_split=9, n_estimators=344;, score=0.679 total time= 3.6min\n",
      "[CV 5/5] END learning_rate=0.7859523653146779, max_depth=12, min_samples_leaf=4, min_samples_split=9, n_estimators=344;, score=0.676 total time= 3.6min\n",
      "[CV 4/5] END learning_rate=0.7859523653146779, max_depth=12, min_samples_leaf=4, min_samples_split=9, n_estimators=344;, score=0.678 total time= 3.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END learning_rate=0.768730400864134, max_depth=25, min_samples_leaf=1, min_samples_split=6, n_estimators=345;, score=0.701 total time= 4.0min\n",
      "[CV 2/5] END learning_rate=0.768730400864134, max_depth=25, min_samples_leaf=1, min_samples_split=6, n_estimators=345;, score=0.702 total time= 4.1min\n",
      "[CV 5/5] END learning_rate=0.768730400864134, max_depth=25, min_samples_leaf=1, min_samples_split=6, n_estimators=345;, score=0.695 total time= 4.2min\n",
      "[CV 3/5] END learning_rate=0.768730400864134, max_depth=25, min_samples_leaf=1, min_samples_split=6, n_estimators=345;, score=0.700 total time= 4.2min\n",
      "[CV 1/5] END learning_rate=0.768730400864134, max_depth=25, min_samples_leaf=1, min_samples_split=6, n_estimators=345;, score=0.699 total time= 4.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END learning_rate=0.029452628807433972, max_depth=6, min_samples_leaf=10, min_samples_split=6, n_estimators=295;, score=0.697 total time= 1.5min\n",
      "[CV 2/5] END learning_rate=0.029452628807433972, max_depth=6, min_samples_leaf=10, min_samples_split=6, n_estimators=295;, score=0.699 total time= 1.5min\n",
      "[CV 3/5] END learning_rate=0.029452628807433972, max_depth=6, min_samples_leaf=10, min_samples_split=6, n_estimators=295;, score=0.703 total time= 1.5min\n",
      "[CV 5/5] END learning_rate=0.029452628807433972, max_depth=6, min_samples_leaf=10, min_samples_split=6, n_estimators=295;, score=0.698 total time= 1.5min\n",
      "[CV 4/5] END learning_rate=0.029452628807433972, max_depth=6, min_samples_leaf=10, min_samples_split=6, n_estimators=295;, score=0.707 total time= 1.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.08233282209215016, max_depth=27, min_samples_leaf=10, min_samples_split=9, n_estimators=274;, score=0.703 total time= 4.7min\n",
      "[CV 1/5] END learning_rate=0.08233282209215016, max_depth=27, min_samples_leaf=10, min_samples_split=9, n_estimators=274;, score=0.701 total time= 4.7min\n",
      "[CV 5/5] END learning_rate=0.08233282209215016, max_depth=27, min_samples_leaf=10, min_samples_split=9, n_estimators=274;, score=0.701 total time= 4.7min\n",
      "[CV 2/5] END learning_rate=0.08233282209215016, max_depth=27, min_samples_leaf=10, min_samples_split=9, n_estimators=274;, score=0.707 total time= 4.7min\n",
      "[CV 4/5] END learning_rate=0.08233282209215016, max_depth=27, min_samples_leaf=10, min_samples_split=9, n_estimators=274;, score=0.705 total time= 4.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.2697099254742119, max_depth=18, min_samples_leaf=2, min_samples_split=7, n_estimators=325;, score=0.700 total time= 4.0min\n",
      "[CV 4/5] END learning_rate=0.2697099254742119, max_depth=18, min_samples_leaf=2, min_samples_split=7, n_estimators=325;, score=0.704 total time= 4.0min\n",
      "[CV 2/5] END learning_rate=0.2697099254742119, max_depth=18, min_samples_leaf=2, min_samples_split=7, n_estimators=325;, score=0.705 total time= 4.0min\n",
      "[CV 1/5] END learning_rate=0.2697099254742119, max_depth=18, min_samples_leaf=2, min_samples_split=7, n_estimators=325;, score=0.707 total time= 4.0min\n",
      "[CV 5/5] END learning_rate=0.2697099254742119, max_depth=18, min_samples_leaf=2, min_samples_split=7, n_estimators=325;, score=0.704 total time= 4.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END learning_rate=0.03651612206199192, max_depth=6, min_samples_leaf=10, min_samples_split=4, n_estimators=280;, score=0.698 total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.03651612206199192, max_depth=6, min_samples_leaf=10, min_samples_split=4, n_estimators=280;, score=0.707 total time= 1.4min\n",
      "[CV 5/5] END learning_rate=0.03651612206199192, max_depth=6, min_samples_leaf=10, min_samples_split=4, n_estimators=280;, score=0.700 total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.03651612206199192, max_depth=6, min_samples_leaf=10, min_samples_split=4, n_estimators=280;, score=0.703 total time= 1.4min\n",
      "[CV 4/5] END learning_rate=0.03651612206199192, max_depth=6, min_samples_leaf=10, min_samples_split=4, n_estimators=280;, score=0.710 total time= 1.4min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END learning_rate=0.030823694722342757, max_depth=7, min_samples_leaf=5, min_samples_split=9, n_estimators=307;, score=0.701 total time= 1.8min\n",
      "[CV 3/5] END learning_rate=0.030823694722342757, max_depth=7, min_samples_leaf=5, min_samples_split=9, n_estimators=307;, score=0.709 total time= 1.8min\n",
      "[CV 4/5] END learning_rate=0.030823694722342757, max_depth=7, min_samples_leaf=5, min_samples_split=9, n_estimators=307;, score=0.712 total time= 1.8min\n",
      "[CV 2/5] END learning_rate=0.030823694722342757, max_depth=7, min_samples_leaf=5, min_samples_split=9, n_estimators=307;, score=0.706 total time= 1.8min\n",
      "[CV 5/5] END learning_rate=0.030823694722342757, max_depth=7, min_samples_leaf=5, min_samples_split=9, n_estimators=307;, score=0.699 total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.021914147070182882, max_depth=8, min_samples_leaf=4, min_samples_split=9, n_estimators=350;, score=0.709 total time= 2.2min\n",
      "[CV 4/5] END learning_rate=0.021914147070182882, max_depth=8, min_samples_leaf=4, min_samples_split=9, n_estimators=350;, score=0.711 total time= 2.2min\n",
      "[CV 5/5] END learning_rate=0.021914147070182882, max_depth=8, min_samples_leaf=4, min_samples_split=9, n_estimators=350;, score=0.702 total time= 2.2min\n",
      "[CV 2/5] END learning_rate=0.021914147070182882, max_depth=8, min_samples_leaf=4, min_samples_split=9, n_estimators=350;, score=0.706 total time= 2.2min\n",
      "[CV 1/5] END learning_rate=0.021914147070182882, max_depth=8, min_samples_leaf=4, min_samples_split=9, n_estimators=350;, score=0.701 total time= 2.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END learning_rate=0.08760826083645255, max_depth=24, min_samples_leaf=1, min_samples_split=6, n_estimators=339;, score=0.698 total time= 6.8min\n",
      "[CV 2/5] END learning_rate=0.08760826083645255, max_depth=24, min_samples_leaf=1, min_samples_split=6, n_estimators=339;, score=0.702 total time= 6.9min\n",
      "[CV 1/5] END learning_rate=0.08760826083645255, max_depth=24, min_samples_leaf=1, min_samples_split=6, n_estimators=339;, score=0.704 total time= 6.9min\n",
      "[CV 3/5] END learning_rate=0.08760826083645255, max_depth=24, min_samples_leaf=1, min_samples_split=6, n_estimators=339;, score=0.701 total time= 6.9min\n",
      "[CV 5/5] END learning_rate=0.08760826083645255, max_depth=24, min_samples_leaf=1, min_samples_split=6, n_estimators=339;, score=0.702 total time= 7.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END learning_rate=0.5253971998047399, max_depth=25, min_samples_leaf=1, min_samples_split=3, n_estimators=286;, score=0.701 total time= 3.9min\n",
      "[CV 2/5] END learning_rate=0.5253971998047399, max_depth=25, min_samples_leaf=1, min_samples_split=3, n_estimators=286;, score=0.705 total time= 3.9min\n",
      "[CV 5/5] END learning_rate=0.5253971998047399, max_depth=25, min_samples_leaf=1, min_samples_split=3, n_estimators=286;, score=0.700 total time= 4.0min\n",
      "[CV 3/5] END learning_rate=0.5253971998047399, max_depth=25, min_samples_leaf=1, min_samples_split=3, n_estimators=286;, score=0.702 total time= 4.0min\n",
      "[CV 1/5] END learning_rate=0.5253971998047399, max_depth=25, min_samples_leaf=1, min_samples_split=3, n_estimators=286;, score=0.701 total time= 4.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.060104513016074265, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=252;, score=0.684 total time= 8.3min\n",
      "[CV 1/5] END learning_rate=0.060104513016074265, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=252;, score=0.682 total time= 8.7min\n",
      "[CV 4/5] END learning_rate=0.060104513016074265, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=252;, score=0.679 total time= 8.8min\n",
      "[CV 5/5] END learning_rate=0.060104513016074265, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=252;, score=0.681 total time= 8.9min\n",
      "[CV 2/5] END learning_rate=0.060104513016074265, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=252;, score=0.678 total time= 9.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 3/5] END learning_rate=0.020000000000000004, max_depth=21, min_samples_leaf=9, min_samples_split=10, n_estimators=255;, score=0.710 total time= 3.9min\n",
      "[CV 4/5] END learning_rate=0.020000000000000004, max_depth=21, min_samples_leaf=9, min_samples_split=10, n_estimators=255;, score=0.704 total time= 3.9min\n",
      "[CV 2/5] END learning_rate=0.020000000000000004, max_depth=21, min_samples_leaf=9, min_samples_split=10, n_estimators=255;, score=0.709 total time= 3.9min\n",
      "[CV 5/5] END learning_rate=0.020000000000000004, max_depth=21, min_samples_leaf=9, min_samples_split=10, n_estimators=255;, score=0.707 total time= 3.9min\n",
      "[CV 1/5] END learning_rate=0.020000000000000004, max_depth=21, min_samples_leaf=9, min_samples_split=10, n_estimators=255;, score=0.711 total time= 3.9min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END learning_rate=0.33994377622821875, max_depth=11, min_samples_leaf=7, min_samples_split=10, n_estimators=274;, score=0.704 total time= 2.4min\n",
      "[CV 4/5] END learning_rate=0.33994377622821875, max_depth=11, min_samples_leaf=7, min_samples_split=10, n_estimators=274;, score=0.703 total time= 2.4min\n",
      "[CV 5/5] END learning_rate=0.33994377622821875, max_depth=11, min_samples_leaf=7, min_samples_split=10, n_estimators=274;, score=0.699 total time= 2.4min\n",
      "[CV 3/5] END learning_rate=0.33994377622821875, max_depth=11, min_samples_leaf=7, min_samples_split=10, n_estimators=274;, score=0.702 total time= 2.4min\n",
      "[CV 2/5] END learning_rate=0.33994377622821875, max_depth=11, min_samples_leaf=7, min_samples_split=10, n_estimators=274;, score=0.701 total time= 2.4min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "fitted_pipelines = []\n",
    "for key in preprocessors:\n",
    "    model = fit_model_via_pipeline(key, preprocessors[key], opt)\n",
    "    fitted_pipelines.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best preprocessor: target_enc_cat, score: 0.6809347479902534\n"
     ]
    }
   ],
   "source": [
    "best_pipeline = max(fitted_pipelines, key=lambda x:x.score)\n",
    "#best_preprocessor_key = 'target_enc_cat'\n",
    "print(f\"The best preprocessor: {best_pipeline.name}, score: {best_pipeline.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = best_pipeline.pipeline\n",
    "preds_valid = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation data: 0.6809347479902534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"Score on validation data: {f1_score(y_valid, preds_valid, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/test_values.csv', index_col='building_id')\n",
    "# Drop building_id (index)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "fixup_geo_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "300051                  3\n",
       "99355                   2\n",
       "890251                  2\n",
       "745817                  1\n",
       "421793                  3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_format = pd.read_csv('../data/submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=preds_test,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsrPython11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
